359 0.0
361 0.0
362 1.0
364 0.0
366 1.0
367 1.0
387 1.0
388 1.0
422 0.0
423 0.0
423_token_31_fp16 0.0
428 0.0
429 0.0
441 0.0
449 0.0
460 1.0
462 0.0
471 0.4283729905961321
473 1.0
479 1.0
490 1.0
492 1.0
493 1.0
498 0.0
499 0.0
501 0.0
502 0.0
502_token_27_fp32 0.0
503 1.0
503_token_32_fp16 1.0
504 1.0
506 1.0
507 1.0
508 1.0
530 0.0
532 0.0
533 1.0
535 1.0
543 1.0
544 1.0
587 1.0
588 1.0
593 0.0
594 0.0
620 1.0
631 1.0
633 1.0
642 0.7071067811865476
644 1.0
650 1.0
661 1.0
663 0.5773502691896257
664 0.5773502691896257
669 0.0
670 0.0
672 0.0
673 0.0
674 0.0
675 0.0
676 0.8269052146305295
677 0.8269052146305295
678 0.0
680 1.0
681 0.5721775087542044
682 0.5721775087542044
683 1.0
684 1.0
685 1.0
688 1.0
689 0.7191364874106868
694 0.687877467169716
695 0.1565580108156219
696 0.6725157563171542
697 0.2852751018035229
698 1.0
699 1.0
700 1.0
702 1.0
705 1.0
706 0.5035770432478277
711 0.8612787645430711
712 1.0
713 1.0
714 1.0
715 1.0
716 1.0
727 1.0
732 1.0
740 1.0
741 1.0
743 1.0
744 0.0
745 0.0
747 1.0
748 0.36602540378443843
750 0.38725318225106853
762 1.0
767 1.0
775 1.0
776 1.0
778 1.0
779 0.0
780 0.0
783 0.0
785 0.0
Gemm_629_Grad/ReduceSum_695_grad_for_model_.twinbert_simmodel.ff_dense10.bias_fp16 0.0
Gemm_629_Grad/dC_reduced 0.0
MatMul_310_Grad/A_reshape_2d 0.0
MatMul_313_Grad/A_reshape_2d 0.0
MatMul_316_Grad/A_reshape_2d 0.0
MatMul_386_Grad/A_reshape_2d 0.0
MatMul_404_Grad/A_reshape_2d 1.0
MatMul_415_Grad/A_reshape_2d 0.4283729905961321
MatMul_433_Grad/A_reshape_2d 1.0
MatMul_447_Grad/A_reshape_2d 1.0
MatMul_478_Grad/A_reshape_2d 1.0
MatMul_481_Grad/A_reshape_2d 1.0
MatMul_484_Grad/A_reshape_2d 1.0
MatMul_572_Grad/A_reshape_2d 1.0
MatMul_583_Grad/A_reshape_2d 0.7071067811865476
MatMul_601_Grad/A_reshape_2d 1.0
Max_638_Grad/Mask_Cast_0 0.0
Max_638_Grad/Mask_Cast_1 0.0
Pow_680_Grad/Mul_Pow_I0_I1 0.682259126853684
Pow_680_Grad/Pow_I0 0.36602540378443843
Pow_715_Grad/Mul_Pow_I0_I1 0.0
Pow_715_Grad/Pow_I0 0.0
Tanh_449_Grad/Squared_Y 1.0
Tanh_449_Grad/Sub_Squared_Y 1.0
Tanh_617_Grad/Squared_Y 1.0
Tanh_617_Grad/Sub_Squared_Y 1.0
batch_norm_dead_output-1068 0.0
batch_norm_dead_output-1069 0.0
batch_norm_dead_output-1104 1.0
batch_norm_dead_output-1105 0.3660254037844387
label 1.0
model_.twinbert_simmodel.ff_dense00.bias 0.0
model_.twinbert_simmodel.ff_dense00.bias_fp16 0.0
model_.twinbert_simmodel.ff_dense00.weight 1.0
model_.twinbert_simmodel.ff_dense00.weight_fp16 1.0
model_.twinbert_simmodel.ff_dense00.weight_fp16_grad 0.7071067811865476
model_.twinbert_simmodel.ff_dense01.bias 0.0
model_.twinbert_simmodel.ff_dense01.bias_fp16 0.0
model_.twinbert_simmodel.ff_dense01.weight_fp16 1.0
model_.twinbert_simmodel.ff_dense10.bias 1.0
model_.twinbert_simmodel.ff_dense10.bias_fp16 1.0
model_.twinbert_simmodel.ff_dense10.weight 1.0
model_.twinbert_simmodel.ff_dense10.weight_fp16 1.0
model_.twinbert_simmodel.ff_dense10.weight_fp16_grad 1.0
model_.twinbert_simmodel.ff_dense11.bias 0.0
model_.twinbert_simmodel.ff_dense11.bias_fp16 0.0
model_.twinbert_simmodel.ff_dense11.weight 1.0
model_.twinbert_simmodel.ff_dense11.weight_fp16 1.0
model_.twinbert_simmodel.ff_dense20.weight 1.0
model_.twinbert_simmodel.ff_dense20.weight_fp16 1.0
model_.twinbert_simmodel.ff_dense20.weight_fp16_grad 1.0
model_.twinbert_simmodel.ff_dense21.weight 1.0
model_.twinbert_simmodel.ff_dense21.weight_fp16 1.0
model_.twinbert_simmodel.qbert_sentencoder.embeddings.position_embeddings.weight 0.0
model_.twinbert_simmodel.qbert_sentencoder.embeddings.position_embeddings.weight_fp16 0.0
model_.twinbert_simmodel.qbert_sentencoder.embeddings.word_embeddings.weight 1.0
model_.twinbert_simmodel.qbert_sentencoder.embeddings.word_embeddings.weight_fp16 1.0
model_.twinbert_simmodel.qbert_sentencoder.encoder.layer.0.attention.output.dense.weight 1.0
model_.twinbert_simmodel.qbert_sentencoder.encoder.layer.0.attention.output.dense.weight_fp16 1.0
model_.twinbert_simmodel.qbert_sentencoder.encoder.layer.0.attention.self.query.weight 1.0
model_.twinbert_simmodel.qbert_sentencoder.encoder.layer.0.attention.self.query.weight_fp16 1.0
model_.twinbert_simmodel.qbert_sentencoder.encoder.layer.0.attention.self.value.weight 1.0
model_.twinbert_simmodel.qbert_sentencoder.encoder.layer.0.attention.self.value.weight_fp16 1.0
model_.twinbert_simmodel.qbert_sentencoder.encoder.layer.0.intermediate.dense.weight 1.0
model_.twinbert_simmodel.qbert_sentencoder.encoder.layer.0.intermediate.dense.weight_fp16 1.0
model_.twinbert_simmodel.qbert_sentencoder.encoder.layer.0.output.dense.weight 1.0
model_.twinbert_simmodel.qbert_sentencoder.encoder.layer.0.output.dense.weight_fp16 1.0
model_.twinbert_simmodel.qdownscale.bias 1.0
model_.twinbert_simmodel.qdownscale.bias_fp16 1.0
model_.twinbert_simmodel.qdownscale.weight 1.0
model_.twinbert_simmodel.qdownscale.weight_fp16 1.0
model_.twinbert_simmodel.qpooler.weighting.bias 0.0
model_.twinbert_simmodel.qpooler.weighting.bias_fp16 0.0
model_.twinbert_simmodel.qpooler.weighting.weight 0.0
model_.twinbert_simmodel.qpooler.weighting.weight_fp16 0.0
model_.twinbert_simmodel.res_bn0.bias_fp16_grad 0.17819697934630022
model_.twinbert_simmodel.res_bn0.running_var_fp16 1.0
model_.twinbert_simmodel.res_bn0.weight_fp16_grad 0.0
model_.twinbert_simmodel.res_bn1.running_var_fp16 1.0
saved_inv_std_var 0.8742412365042523
saved_inv_std_var_token_3 1.0
saved_inv_std_var_token_6 0.7740207601423642
saved_inv_std_var_token_9 1.0
